Optimizing an ML Pipeline in Azure
Overview
This project is part of the Udacity Azure ML Nanodegree. In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model. This model is then compared to an Azure AutoML run.

Summary
"This dataset contains data about prospective customer such as age,job,marital,education, and whether they subscribe to a term deposit with the bank. we seek to predict based on prospective customer data which kind of customer characteristic that they will subscribe to a term deposit with the bank"

"The best performing model was a voting assembly using AutoML"

Scikit-learn Pipeline
Pipeline architecture including data has been cleanse and normalize, hyperparameter tuning using taking different set of values for C where C = 1/Î», (0.2, 0,5, 1) and for maximum number of iterations using max_iter (25, 50, 100). For classification algorithm, the model use LogisticRegression.

The benefits of the parameter sampler is to get a perfect trade-off between low-bias and high-variance and tries to minimize the loss by choose the maximum number of iterations

The benefits of the early stopping policy is saving us from continuing to explore hyperparameters that don't show promise of helping reach our target metric

AutoML
The best model generated by AutoML is voting assembly that shows two most important variable is duration and employee variable rate. weighted_accuracy of the model is 0.955, f1_score_weighted is 0.914, precision_score_weighted is 0.912. From confusion matrix table, of the 22939 customer who subscribe to a term deposit with the bank, the model judged that 22569 subscribe, and of the 2221 does not subscribe, it predicted that 1591 not subscribe.  

Pipeline comparison
AutoML model produced more accurate model which is more than 90%, our hyperparameter tuning model is only 71%. AutoML produce more accurate because the model review more paramters other than C and max_iter, and also more choice, which is only three in hyperparameter tuning on C and max_iter.

Future work
For hyperparameter tuning it would be better we review other parameter such as intercept scaling and verbose. For AutoML we could increase experiment_timeout_minutes. Both suggestion will improve the model, as the model will not standart parameter and there will be more time for run submission to find more accurate model.

Proof of cluster clean up
Compute cluster has been deleted as mentioned in the code
